{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stage II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import xlearn as xl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# read the config file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATA_PATH = config['DATA_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_FE = dd.read_csv(DATA_PATH+'tr_FE.csv').compute()\n",
    "features = dd.read_csv('feature.csv').compute()\n",
    "feature_columns = features.head(30)['feature'].tolist()\n",
    "\n",
    "X = tr_FE[feature_columns]\n",
    "y = tr_FE['click']\n",
    "\n",
    "X = X.astype({col: 'int32' for col in X.select_dtypes('bool').columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of the model is 0.635125340356276\n",
      "The log loss is 0.43827477415305977\n"
     ]
    }
   ],
   "source": [
    "skLR = LogisticRegression(max_iter=100,random_state=42)\n",
    "skLR.fit(X_train,y_train)\n",
    "# Predict the probabilities of the test set\n",
    "y_pred_proba = skLR.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "loss = log_loss(y_test,y_pred_proba)\n",
    "print(f'The AUC of the model is {auc}')\n",
    "print(f'The log loss is {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 1293726 samples, validate on 323432 samples, 5054 steps per epoch\n",
      "Epoch 1/10\n",
      "31s - loss:  0.4325 - auc:  0.6550 - val_auc:  0.6763\n",
      "Epoch 2/10\n",
      "31s - loss:  0.4231 - auc:  0.6832 - val_auc:  0.6924\n",
      "Epoch 3/10\n",
      "32s - loss:  0.4193 - auc:  0.6949 - val_auc:  0.6997\n",
      "Epoch 4/10\n",
      "31s - loss:  0.4172 - auc:  0.7011 - val_auc:  0.7026\n",
      "Epoch 5/10\n",
      "31s - loss:  0.4155 - auc:  0.7056 - val_auc:  0.7072\n",
      "Epoch 6/10\n",
      "31s - loss:  0.4143 - auc:  0.7085 - val_auc:  0.7040\n",
      "Epoch 7/10\n",
      "30s - loss:  0.4135 - auc:  0.7105 - val_auc:  0.7080\n",
      "Epoch 8/10\n",
      "33s - loss:  0.4128 - auc:  0.7120 - val_auc:  0.7068\n",
      "Epoch 9/10\n",
      "32s - loss:  0.4123 - auc:  0.7132 - val_auc:  0.7118\n",
      "Epoch 10/10\n",
      "31s - loss:  0.4117 - auc:  0.7144 - val_auc:  0.7134\n",
      "AUC:  0.715179730959022\n",
      "Log Loss:  0.4118379257847679\n"
     ]
    }
   ],
   "source": [
    "from deepctr_torch.inputs import get_feature_names, DenseFeat\n",
    "from deepctr_torch.models import DeepFM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Convert X and y into a DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "dense_features = df.columns.tolist()\n",
    "dense_features.remove('target')\n",
    "\n",
    "# Preprocessing\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "df[dense_features] = mms.fit_transform(df[dense_features])\n",
    "\n",
    "# Split the data\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Generate feature columns\n",
    "feature_columns = [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "feature_names = get_feature_names(feature_columns)\n",
    "\n",
    "# Convert the data into model input\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}\n",
    "\n",
    "# Create the model\n",
    "model = DeepFM(feature_columns, feature_columns,task='binary',\n",
    "                   l2_reg_embedding=1e-5, device=device)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['auc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_model_input, train['target'].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = model.predict(test_model_input, batch_size=256)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(test['target'].values, y_pred)\n",
    "print(\"AUC: \", auc)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(test['target'].values, y_pred)\n",
    "print(\"Log Loss: \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 1293726 samples, validate on 323432 samples, 5054 steps per epoch\n",
      "Epoch 1/10\n",
      "32s - loss:  0.4331 - auc:  0.6553 - val_auc:  0.6728\n",
      "Epoch 2/10\n",
      "31s - loss:  0.4244 - auc:  0.6805 - val_auc:  0.6853\n",
      "Epoch 3/10\n",
      "32s - loss:  0.4206 - auc:  0.6932 - val_auc:  0.6964\n",
      "Epoch 4/10\n",
      "32s - loss:  0.4180 - auc:  0.7010 - val_auc:  0.6994\n",
      "Epoch 5/10\n",
      "31s - loss:  0.4162 - auc:  0.7060 - val_auc:  0.7044\n",
      "Epoch 6/10\n",
      "32s - loss:  0.4147 - auc:  0.7096 - val_auc:  0.7073\n",
      "Epoch 7/10\n",
      "32s - loss:  0.4138 - auc:  0.7118 - val_auc:  0.7101\n",
      "Epoch 8/10\n",
      "32s - loss:  0.4130 - auc:  0.7138 - val_auc:  0.7083\n",
      "Epoch 9/10\n",
      "31s - loss:  0.4124 - auc:  0.7149 - val_auc:  0.7125\n",
      "Epoch 10/10\n",
      "31s - loss:  0.4119 - auc:  0.7161 - val_auc:  0.7141\n",
      "AUC:  0.717321031219362\n",
      "Log Loss:  0.41103908506793624\n"
     ]
    }
   ],
   "source": [
    "from deepctr_torch.models import WDL\n",
    "\n",
    "# Convert X and y into a DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "dense_features = df.columns.tolist()\n",
    "dense_features.remove('target')\n",
    "\n",
    "# Preprocessing\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "df[dense_features] = mms.fit_transform(df[dense_features])\n",
    "\n",
    "# Split the data\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Generate feature columns\n",
    "feature_columns = [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "feature_names = get_feature_names(feature_columns)\n",
    "\n",
    "# Convert the data into model input\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = WDL(feature_columns, feature_columns,task='binary',\n",
    "                   l2_reg_embedding=1e-5, device=device)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['auc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_model_input, train['target'].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = model.predict(test_model_input, batch_size=256)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(test['target'].values, y_pred)\n",
    "print(\"AUC: \", auc)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(test['target'].values, y_pred)\n",
    "print(\"Log Loss: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
