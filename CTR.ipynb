{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stage I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import xlearn as xl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# read the config file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATA_PATH = config['DATA_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_FE = dd.read_csv(DATA_PATH+'tr_FE.csv').compute()\n",
    "features = dd.read_csv('feature.csv').compute()\n",
    "feature_columns = features.head(30)['feature'].tolist()\n",
    "\n",
    "X = tr_FE[feature_columns]\n",
    "y = tr_FE['click']\n",
    "\n",
    "X = X.astype({col: 'int32' for col in X.select_dtypes('bool').columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data\n",
    "dump_svmlight_file(X_train, y_train, 'train.libsvm')\n",
    "\n",
    "# Convert the test data\n",
    "dump_svmlight_file(X_test, y_test, 'test.libsvm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 1.14 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 0.12 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   1%\u001b[32m      ]\u001b[0m     1                 inf                 inf            0.500000                1.73\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     2                 inf                 inf            0.500000                1.70\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     3                 inf                 inf            0.505588                2.00\n",
      "\u001b[32m[ \u001b[0m   4%\u001b[32m      ]\u001b[0m     4                 inf                 inf            0.473892                2.12\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     5                 inf                 inf            0.500000                1.76\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     6                 inf                 inf            0.516510                1.67\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     7                 inf                 inf            0.500000                1.77\n",
      "\u001b[32m[ \u001b[0m   8%\u001b[32m      ]\u001b[0m     8                 inf                 inf            0.500000                1.74\n",
      "\u001b[32m[ \u001b[0m   9%\u001b[32m      ]\u001b[0m     9                 inf                 inf            0.499472                1.81\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m    10                 inf                 inf            0.499972                1.62\n",
      "\u001b[32m[ \u001b[0m  11%\u001b[32m      ]\u001b[0m    11                 inf                 inf            0.500000                1.57\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m    12                 inf                 inf            0.500000                1.82\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m    13                 inf                 inf            0.503773                1.69\n",
      "\u001b[32m[ \u001b[0m  14%\u001b[32m      ]\u001b[0m    14                 inf                 inf            0.498250                1.70\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m    15                 inf                 inf            0.500000                1.69\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m    16                 inf                 inf            0.518307                1.80\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m    17                 inf                 inf            0.455672                1.60\n",
      "\u001b[32m[ \u001b[0m  18%\u001b[32m      ]\u001b[0m    18                 inf                 inf            0.498352                1.61\n",
      "\u001b[32m[ \u001b[0m  19%\u001b[32m      ]\u001b[0m    19                 inf                 inf            0.500000                1.71\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m    20                 inf                 inf            0.500000                1.78\n",
      "\u001b[32m[ \u001b[0m  21%\u001b[32m      ]\u001b[0m    21                 inf                 inf            0.500000                1.60\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m    22                 inf                 inf            0.500009                1.78\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m    23                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  24%\u001b[32m      ]\u001b[0m    24                 inf                 inf            0.500000                1.69\n",
      "\u001b[32m[ \u001b[0m  25%\u001b[32m      ]\u001b[0m    25                 inf                 inf            0.500000                1.53\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m    26                 inf                 inf            0.500000                1.58\n",
      "\u001b[32m[ \u001b[0m  27%\u001b[32m      ]\u001b[0m    27                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  28%\u001b[32m      ]\u001b[0m    28                 inf                 inf            0.499336                1.72\n",
      "\u001b[32m[ \u001b[0m  28%\u001b[32m      ]\u001b[0m    29                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m    30                 inf                 inf            0.542928                1.75\n",
      "\u001b[32m[ \u001b[0m  31%\u001b[32m      ]\u001b[0m    31                 inf                 inf            0.500004                1.77\n",
      "\u001b[32m[ \u001b[0m  32%\u001b[32m      ]\u001b[0m    32                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    33                 inf                 inf            0.500023                1.73\n",
      "\u001b[32m[ \u001b[0m  34%\u001b[32m      ]\u001b[0m    34                 inf                 inf            0.500000                1.54\n",
      "\u001b[32m[ \u001b[0m  35%\u001b[32m      ]\u001b[0m    35                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    36                 inf                 inf            0.514486                1.70\n",
      "\u001b[32m[ \u001b[0m  37%\u001b[32m      ]\u001b[0m    37                 inf                 inf            0.500000                1.72\n",
      "\u001b[32m[ \u001b[0m  38%\u001b[32m      ]\u001b[0m    38                 inf                 inf            0.480871                1.70\n",
      "\u001b[32m[ \u001b[0m  39%\u001b[32m      ]\u001b[0m    39                 inf                 inf            0.500000                1.78\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    40                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  41%\u001b[32m      ]\u001b[0m    41                 inf                 inf            0.498477                1.67\n",
      "\u001b[32m[ \u001b[0m  42%\u001b[32m      ]\u001b[0m    42                 inf                 inf            0.500000                1.71\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    43                 inf                 inf            0.500000                1.60\n",
      "\u001b[32m[ \u001b[0m  44%\u001b[32m      ]\u001b[0m    44                 inf                 inf            0.500000                1.71\n",
      "\u001b[32m[ \u001b[0m  45%\u001b[32m      ]\u001b[0m    45                 inf                 inf            0.500000                1.59\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    46                 inf                 inf            0.504684                1.63\n",
      "\u001b[32m[ \u001b[0m  47%\u001b[32m      ]\u001b[0m    47                 inf                 inf            0.498326                1.93\n",
      "\u001b[32m[ \u001b[0m  48%\u001b[32m      ]\u001b[0m    48                 inf                 inf            0.500000                1.34\n",
      "\u001b[32m[ \u001b[0m  49%\u001b[32m      ]\u001b[0m    49                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    50                 inf                 inf            0.460290                1.60\n",
      "\u001b[32m[ \u001b[0m  51%\u001b[32m      ]\u001b[0m    51                 inf                 inf            0.517378                1.59\n",
      "\u001b[32m[ \u001b[0m  52%\u001b[32m      ]\u001b[0m    52                 inf                 inf            0.500000                1.80\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    53                 inf                 inf            0.500000                1.51\n",
      "\u001b[32m[ \u001b[0m  54%\u001b[32m      ]\u001b[0m    54                 inf                 inf            0.491501                1.64\n",
      "\u001b[32m[ \u001b[0m  55%\u001b[32m      ]\u001b[0m    55                 inf                 inf            0.500000                1.66\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    56                 inf                 inf            0.500000                1.60\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    57                 inf                 inf            0.440436                1.58\n",
      "\u001b[32m[ \u001b[0m  57%\u001b[32m      ]\u001b[0m    58                 inf                 inf            0.499546                1.58\n",
      "\u001b[32m[ \u001b[0m  59%\u001b[32m      ]\u001b[0m    59                 inf                 inf            0.500000                1.63\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    60                 inf                 inf            0.498274                1.67\n",
      "\u001b[32m[ \u001b[0m  61%\u001b[32m      ]\u001b[0m    61                 inf                 inf            0.500000                1.70\n",
      "\u001b[32m[ \u001b[0m  62%\u001b[32m      ]\u001b[0m    62                 inf                 inf            0.500105                1.54\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    63                 inf                 inf            0.500000                1.66\n",
      "\u001b[32m[ \u001b[0m  64%\u001b[32m      ]\u001b[0m    64                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  65%\u001b[32m      ]\u001b[0m    65                 inf                 inf            0.500000                1.64\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    66                 inf                 inf            0.500000                1.65\n",
      "\u001b[32m[ \u001b[0m  67%\u001b[32m      ]\u001b[0m    67                 inf                 inf            0.447188                1.49\n",
      "\u001b[32m[ \u001b[0m  68%\u001b[32m      ]\u001b[0m    68                 inf                 inf            0.500000                1.69\n",
      "\u001b[32m[ \u001b[0m  69%\u001b[32m      ]\u001b[0m    69                 inf                 inf            0.500000                1.65\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    70                 inf                 inf            0.500000                1.36\n",
      "\u001b[32m[ \u001b[0m  71%\u001b[32m      ]\u001b[0m    71                 inf                 inf            0.500000                1.65\n",
      "\u001b[32m[ \u001b[0m  72%\u001b[32m      ]\u001b[0m    72                 inf                 inf            0.500000                1.47\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    73                 inf                 inf            0.481053                1.57\n",
      "\u001b[32m[ \u001b[0m  74%\u001b[32m      ]\u001b[0m    74                 inf                 inf            0.500000                1.62\n",
      "\u001b[32m[ \u001b[0m  75%\u001b[32m      ]\u001b[0m    75                 inf                 inf            0.437250                1.63\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    76                 inf                 inf            0.499893                1.59\n",
      "\u001b[32m[ \u001b[0m  77%\u001b[32m      ]\u001b[0m    77                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  78%\u001b[32m      ]\u001b[0m    78                 inf                 inf            0.480468                1.57\n",
      "\u001b[32m[ \u001b[0m  79%\u001b[32m      ]\u001b[0m    79                 inf                 inf            0.500000                1.71\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    80                 inf                 inf            0.500000                1.75\n",
      "\u001b[32m[ \u001b[0m  81%\u001b[32m      ]\u001b[0m    81                 inf                 inf            0.500000                1.45\n",
      "\u001b[32m[ \u001b[0m  82%\u001b[32m      ]\u001b[0m    82                 inf                 inf            0.500000                1.59\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    83                 inf                 inf            0.499456                1.62\n",
      "\u001b[32m[ \u001b[0m  84%\u001b[32m      ]\u001b[0m    84                 inf                 inf            0.498328                1.63\n",
      "\u001b[32m[ \u001b[0m  85%\u001b[32m      ]\u001b[0m    85                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    86                 inf                 inf            0.500000                1.36\n",
      "\u001b[32m[ \u001b[0m  87%\u001b[32m      ]\u001b[0m    87                 inf                 inf            0.481100                1.64\n",
      "\u001b[32m[ \u001b[0m  88%\u001b[32m      ]\u001b[0m    88                 inf                 inf            0.500000                1.70\n",
      "\u001b[32m[ \u001b[0m  89%\u001b[32m      ]\u001b[0m    89                 inf                 inf            0.500000                1.52\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    90                 inf                 inf            0.500000                1.66\n",
      "\u001b[32m[ \u001b[0m  91%\u001b[32m      ]\u001b[0m    91                 inf                 inf            0.500000                1.58\n",
      "\u001b[32m[ \u001b[0m  92%\u001b[32m      ]\u001b[0m    92                 inf                 inf            0.484116                1.61\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    93                 inf                 inf            0.500000                1.59\n",
      "\u001b[32m[ \u001b[0m  94%\u001b[32m      ]\u001b[0m    94                 inf                 inf            0.500000                1.61\n",
      "\u001b[32m[ \u001b[0m  95%\u001b[32m      ]\u001b[0m    95                 inf                 inf            0.500000                1.63\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    96                 inf                 inf            0.500000                1.70\n",
      "\u001b[32m[ \u001b[0m  97%\u001b[32m      ]\u001b[0m    97                 inf                 inf            0.530489                1.65\n",
      "\u001b[32m[ \u001b[0m  98%\u001b[32m      ]\u001b[0m    98                 inf                 inf            0.498266                1.72\n",
      "\u001b[32m[ \u001b[0m  99%\u001b[32m      ]\u001b[0m    99                 inf                 inf            0.518679                1.60\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m   100                 inf                 inf            0.468216                1.50\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 30, best AUC: 0.542928\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 166.15 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: linear\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.13 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: inf\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.28 (sec)\u001b[0m\n",
      "AUC:  0.4570805183963875\n",
      "Log Loss:  23.54422898470199\n"
     ]
    }
   ],
   "source": [
    "LR = xl.create_linear()\n",
    "# Set the parameters of the model\n",
    "LR.setTrain(\"train.libsvm\")  # Training data\n",
    "LR.setValidate(\"test.libsvm\")  # Validation data\n",
    "\n",
    "# Train the model\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.002, 'metric':'auc','epoch': 100, 'opt':'sgd'}\n",
    "LR.fit(param, \"./model.out\")\n",
    "\n",
    "# Predict the test data\n",
    "LR.setTest(\"test.libsvm\")  # Test data\n",
    "LR.setSigmoid()  # Convert output to probability\n",
    "LR.predict(\"./model.out\", \"./output.txt\")\n",
    "\n",
    "# Load the prediction results\n",
    "y_pred = np.loadtxt(\"./output.txt\")\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC: \", auc)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Log Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 1.02 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 0.59 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   1%\u001b[32m      ]\u001b[0m     1            0.502280            0.473380            0.543797                3.12\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     2            0.500413            0.481356            0.558767                3.01\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     3            0.493651            0.453912            0.553122                3.18\n",
      "\u001b[32m[ \u001b[0m   4%\u001b[32m      ]\u001b[0m     4            0.491268            0.463753            0.553941                2.78\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     5            0.497398            0.454877            0.554721                3.17\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     6            0.503716            0.458288            0.556993                3.37\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     7            0.505112            0.473359            0.552721                3.29\n",
      "\u001b[32m[ \u001b[0m   8%\u001b[32m      ]\u001b[0m     8            0.507306            0.457282            0.553740                3.46\n",
      "\u001b[32m[ \u001b[0m   9%\u001b[32m      ]\u001b[0m     9            0.506105            0.475732            0.559566                3.34\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m    10            0.501670            0.484519            0.561379                3.44\n",
      "\u001b[32m[ \u001b[0m  11%\u001b[32m      ]\u001b[0m    11            0.512229            0.457763            0.542746                3.68\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m    12            0.512964            0.471419            0.555083                3.57\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m    13            0.512539            0.514815            0.533092                3.61\n",
      "\u001b[32m[ \u001b[0m  14%\u001b[32m      ]\u001b[0m    14            0.511919            0.453319            0.558755                3.60\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m    15            0.513952            0.453972            0.553348                3.60\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m    16            0.501085            0.453651            0.558718                3.46\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m    17            0.510222            0.463020            0.554619                3.57\n",
      "\u001b[32m[ \u001b[0m  18%\u001b[32m      ]\u001b[0m    18            0.502319            0.455718            0.544485                3.43\n",
      "\u001b[32m[ \u001b[0m  19%\u001b[32m      ]\u001b[0m    19            0.514273            0.454162            0.556134                3.62\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m    20            0.510966            0.457004            0.542895                3.51\n",
      "\u001b[32m[ \u001b[0m  21%\u001b[32m      ]\u001b[0m    21            0.510500            0.464402            0.559087                3.51\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m    22            0.515054            0.454492            0.556060                3.61\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m    23            0.517901            0.456782            0.553517                3.76\n",
      "\u001b[32m[ \u001b[0m  24%\u001b[32m      ]\u001b[0m    24            0.507849            0.473608            0.497200                3.64\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 10, best AUC: 0.561379\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 83.40 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: fm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.13 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.484519\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.32 (sec)\u001b[0m\n",
      "AUC:  0.5613705978329273\n",
      "Log Loss:  0.48452009117110534\n"
     ]
    }
   ],
   "source": [
    "# Create FM model\n",
    "fm_model = xl.create_fm()\n",
    "\n",
    "# Set the parameters of the model\n",
    "fm_model.setTrain(\"train.libsvm\")  # Training data\n",
    "fm_model.setValidate(\"test.libsvm\")  # Validation data\n",
    "\n",
    "# Train the model\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.002, 'metric':'auc','epoch': 100, 'opt':'sgd'}\n",
    "fm_model.fit(param, \"./model.out\")\n",
    "\n",
    "# Predict the test data\n",
    "fm_model.setTest(\"test.libsvm\")  # Test data\n",
    "fm_model.setSigmoid()  # Convert output to probability\n",
    "fm_model.predict(\"./model.out\", \"./output.txt\")\n",
    "\n",
    "# Load the prediction results\n",
    "y_pred = np.loadtxt(\"./output.txt\")\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC: \", auc)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(y_test, y_pred)\n",
    "\n",
    "print(\"Log Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 1\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 1.45 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 0.59 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   1%\u001b[32m      ]\u001b[0m     1            0.509321            0.453507            0.549515               20.47\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     2            0.492372            0.457084            0.550244               19.80\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     3            0.518138            0.467834            0.560401               21.20\n",
      "\u001b[32m[ \u001b[0m   4%\u001b[32m      ]\u001b[0m     4            0.527177            0.461337            0.563967               24.09\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     5            0.536873            0.465289            0.553164               29.22\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     6            0.593508            0.453964            0.550318               35.38\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m     7            0.602586            0.454825            0.534904               34.51\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 4, best AUC: 0.563967\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 186.13 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 30\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 1\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libsvm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.12 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.461337\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.32 (sec)\u001b[0m\n",
      "AUC:  0.564025918236759\n",
      "Log Loss:  0.46133508130186884\n"
     ]
    }
   ],
   "source": [
    "# Create FM model\n",
    "fm_model = xl.create_ffm()\n",
    "\n",
    "# Set the parameters of the model\n",
    "fm_model.setTrain(\"train.libsvm\")  # Training data\n",
    "fm_model.setValidate(\"test.libsvm\")  # Validation data\n",
    "\n",
    "# Train the model\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.002, 'metric':'auc','epoch': 100,'opt':'sgd'}\n",
    "fm_model.fit(param, \"./model.out\")\n",
    "\n",
    "# Predict the test data\n",
    "fm_model.setTest(\"test.libsvm\")  # Test data\n",
    "fm_model.setSigmoid()  # Convert output to probability\n",
    "fm_model.predict(\"./model.out\", \"./output.txt\")\n",
    "\n",
    "# Load the prediction results\n",
    "y_pred = np.loadtxt(\"./output.txt\")\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC: \", auc)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(y_test, y_pred)\n",
    "print(\"Log Loss: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
